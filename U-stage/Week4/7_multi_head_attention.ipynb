{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "7_multi_head_attention.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KsBGZpKkWki"
      },
      "source": [
        "##**7. Multi-head Attention**\r\n",
        "1. Multi-head attention 및 self-attention 구현.\r\n",
        "2. 각 과정에서 일어나는 연산과 input/output 형태 이해."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8qRU5DFY2OM8"
      },
      "source": [
        "### **필요 패키지 import**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDtMioSQQ1bB"
      },
      "source": [
        "from torch import nn\r\n",
        "from torch.nn import functional as F\r\n",
        "from tqdm import tqdm\r\n",
        "\r\n",
        "import torch\r\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBiZObgRep_Q"
      },
      "source": [
        "### **데이터 전처리**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e9ULZIqTenSc"
      },
      "source": [
        "pad_id = 0\r\n",
        "vocab_size = 100\r\n",
        "\r\n",
        "data = [\r\n",
        "  [62, 13, 47, 39, 78, 33, 56, 13, 39, 29, 44, 86, 71, 36, 18, 75],\r\n",
        "  [60, 96, 51, 32, 90],\r\n",
        "  [35, 45, 48, 65, 91, 99, 92, 10, 3, 21, 54],\r\n",
        "  [75, 51],\r\n",
        "  [66, 88, 98, 47],\r\n",
        "  [21, 39, 10, 64, 21],\r\n",
        "  [98],\r\n",
        "  [77, 65, 51, 77, 19, 15, 35, 19, 23, 97, 50, 46, 53, 42, 45, 91, 66, 3, 43, 10],\r\n",
        "  [70, 64, 98, 25, 99, 53, 4, 13, 69, 62, 66, 76, 15, 75, 45, 34],\r\n",
        "  [20, 64, 81, 35, 76, 85, 1, 62, 8, 45, 99, 77, 19, 43]\r\n",
        "]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Hx3mcivgMyH"
      },
      "source": [
        "def padding(data):\r\n",
        "  max_len = len(max(data, key=len))\r\n",
        "  print(f\"Maximum sequence length: {max_len}\")\r\n",
        "\r\n",
        "  for i, seq in enumerate(tqdm(data)):\r\n",
        "    if len(seq) < max_len:\r\n",
        "      data[i] = seq + [pad_id] * (max_len - len(seq))\r\n",
        "\r\n",
        "  return data, max_len"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3e8FiNvgX60",
        "outputId": "16885bc9-6057-4d33-8fa8-1b168dc3106d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data, max_len = padding(data)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 34865.37it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum sequence length: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwPSIWYugaN0",
        "outputId": "152973d5-551a-464c-ab20-c5104284654c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[62, 13, 47, 39, 78, 33, 56, 13, 39, 29, 44, 86, 71, 36, 18, 75, 0, 0, 0, 0],\n",
              " [60, 96, 51, 32, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [35, 45, 48, 65, 91, 99, 92, 10, 3, 21, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [75, 51, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [66, 88, 98, 47, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [21, 39, 10, 64, 21, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [98, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [77,\n",
              "  65,\n",
              "  51,\n",
              "  77,\n",
              "  19,\n",
              "  15,\n",
              "  35,\n",
              "  19,\n",
              "  23,\n",
              "  97,\n",
              "  50,\n",
              "  46,\n",
              "  53,\n",
              "  42,\n",
              "  45,\n",
              "  91,\n",
              "  66,\n",
              "  3,\n",
              "  43,\n",
              "  10],\n",
              " [70, 64, 98, 25, 99, 53, 4, 13, 69, 62, 66, 76, 15, 75, 45, 34, 0, 0, 0, 0],\n",
              " [20, 64, 81, 35, 76, 85, 1, 62, 8, 45, 99, 77, 19, 43, 0, 0, 0, 0, 0, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwqjACx8iidc"
      },
      "source": [
        "### **Hyperparameter 세팅 및 embedding**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-Ngp2nWimS8"
      },
      "source": [
        "d_model = 512  # model의 hidden size\r\n",
        "num_heads = 8  # head의 개수"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJMi2Xsni5uq"
      },
      "source": [
        "embedding = nn.Embedding(vocab_size, d_model)\r\n",
        "\r\n",
        "# B: batch size, L: maximum sequence length\r\n",
        "batch = torch.LongTensor(data)  # (B, L)\r\n",
        "batch_emb = embedding(batch)  # (B, L, d_model)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tLCUQwojcUb",
        "outputId": "7e8326ca-e1c9-494f-c1c8-62d3e95235c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(batch_emb)\r\n",
        "print(batch_emb.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.2826,  0.1404, -1.8806,  ...,  1.0316,  1.5623, -0.4378],\n",
            "         [-0.6358, -1.4330,  0.0812,  ..., -0.2815, -0.8433, -0.6888],\n",
            "         [-0.5335, -1.2960,  0.2290,  ..., -1.9809, -0.8674, -0.5929],\n",
            "         ...,\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392]],\n",
            "\n",
            "        [[ 1.1400,  0.2889,  0.5718,  ...,  2.4864, -0.2878, -0.5118],\n",
            "         [ 1.0549, -0.4372,  0.7949,  ...,  1.8875, -0.6376, -0.5406],\n",
            "         [-0.3805, -0.2027, -0.8908,  ..., -0.0192, -2.5096, -1.4047],\n",
            "         ...,\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392]],\n",
            "\n",
            "        [[ 1.4028, -1.4137, -0.7341,  ...,  0.1304, -1.5731, -0.9929],\n",
            "         [-1.0511,  1.2357, -0.4694,  ..., -2.0435,  0.4079,  0.3169],\n",
            "         [ 1.2631,  0.1260, -1.9415,  ...,  0.0652,  0.7972, -0.5829],\n",
            "         ...,\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 1.3514,  1.0689, -0.7047,  ..., -2.5868, -2.3588, -0.2955],\n",
            "         [-0.1109,  0.8487, -0.0258,  ..., -0.3017,  0.3422, -1.7129],\n",
            "         [-0.3805, -0.2027, -0.8908,  ..., -0.0192, -2.5096, -1.4047],\n",
            "         ...,\n",
            "         [-0.6443, -1.2490, -0.1063,  ...,  0.7132, -1.0213,  0.1770],\n",
            "         [-0.9161,  0.5669, -1.3835,  ...,  1.2936, -0.2886, -0.6846],\n",
            "         [-0.1413, -1.6852, -0.4336,  ...,  1.0156, -0.7523,  0.9185]],\n",
            "\n",
            "        [[ 0.5095, -0.1686, -0.4067,  ...,  2.2560,  0.2799, -1.1704],\n",
            "         [ 0.3631,  0.6746,  3.1657,  ...,  1.3225,  0.0383,  0.5229],\n",
            "         [ 1.4657, -0.9459, -0.6632,  ..., -0.1558,  2.6244,  1.0930],\n",
            "         ...,\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392]],\n",
            "\n",
            "        [[-0.0421, -0.2451, -0.0806,  ...,  1.8967,  0.3876,  1.0141],\n",
            "         [ 0.3631,  0.6746,  3.1657,  ...,  1.3225,  0.0383,  0.5229],\n",
            "         [-0.1544, -0.0911, -1.0902,  ..., -0.5449,  0.6010, -0.5516],\n",
            "         ...,\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392],\n",
            "         [-1.2422, -0.7566,  0.4933,  ...,  1.1519,  2.0426,  1.5392]]],\n",
            "       grad_fn=<EmbeddingBackward>)\n",
            "torch.Size([10, 20, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Lhx892gmi3"
      },
      "source": [
        "### **Linear transformation & 여러 head로 나누기**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "urXMBRnRgqvw"
      },
      "source": [
        "Multi-head attention 내에서 쓰이는 linear transformation matrix들을 정의합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DWKDqgCgfMk"
      },
      "source": [
        "w_q = nn.Linear(d_model, d_model)\r\n",
        "w_k = nn.Linear(d_model, d_model)\r\n",
        "w_v = nn.Linear(d_model, d_model)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcLuhda7m-Lm"
      },
      "source": [
        "w_0 = nn.Linear(d_model, d_model)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-vSL7PwnV6k",
        "outputId": "cb2afb0e-b8d4-4ad4-932a-e368457bcd08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "q = w_q(batch_emb)  # (B, L, d_model)\r\n",
        "k = w_k(batch_emb)  # (B, L, d_model)\r\n",
        "v = w_v(batch_emb)  # (B, L, d_model)\r\n",
        "\r\n",
        "print(q.shape)\r\n",
        "print(k.shape)\r\n",
        "print(v.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 20, 512])\n",
            "torch.Size([10, 20, 512])\n",
            "torch.Size([10, 20, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wnvlum-LnF1T"
      },
      "source": [
        "Q, k, v를 `num_head`개의 차원 분할된 여러 vector로 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tiOKAv9nEli",
        "outputId": "9fc959ea-6318-47b0-e658-8c1ce812aa08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "batch_size = q.shape[0]\r\n",
        "d_k = d_model // num_heads\r\n",
        "\r\n",
        "q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n",
        "k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n",
        "v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n",
        "\r\n",
        "print(q.shape)\r\n",
        "print(k.shape)\r\n",
        "print(v.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 20, 8, 64])\n",
            "torch.Size([10, 20, 8, 64])\n",
            "torch.Size([10, 20, 8, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tNb2isfn5Cx",
        "outputId": "919971ec-475c-446e-971e-97c453423f0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n",
        "k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n",
        "v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n",
        "\r\n",
        "print(q.shape)\r\n",
        "print(k.shape)\r\n",
        "print(v.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 8, 20, 64])\n",
            "torch.Size([10, 8, 20, 64])\n",
            "torch.Size([10, 8, 20, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWrDA5_Sofad"
      },
      "source": [
        "### **Scaled dot-product self-attention 구현**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w52C4k3Wfl8m"
      },
      "source": [
        "각 head에서 실행되는 self-attetion 과정입니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5waKr0Hfi2K",
        "outputId": "5a4c00c9-d7bf-4a96-ccb5-0bc0d92e5311",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)\r\n",
        "attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, L, L)\r\n",
        "\r\n",
        "print(attn_scores.shape)\r\n",
        "# print(attn_dists)\r\n",
        "print(attn_dists.shape)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 8, 20, 20])\n",
            "torch.Size([10, 8, 20, 20])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttvf1OxQMCLl",
        "outputId": "40af7e55-7979-4390-ae12-016ddc77a365",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "\r\n",
        "v.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 8, 20, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7megouWpgCck",
        "outputId": "442fd201-6a44-4582-9ee3-2eacfa39d363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\r\n",
        "\r\n",
        "print(attn_values.shape)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 8, 20, 64])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmSTaymdg-P_"
      },
      "source": [
        "### **각 head의 결과물 병합**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSdQZCk0hCNd"
      },
      "source": [
        "각 head의 결과물을 concat하고 동일 차원으로 linear transformation합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaK0bpMGhQZ2",
        "outputId": "bc884e94-0308-47d1-f8cf-51b6484dc8db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "attn_values = attn_values.transpose(1, 2)  # (B, L, num_heads, d_k)\r\n",
        "print(attn_values.shape)\r\n",
        "attn_values = attn_values.contiguous().view(batch_size, -1, d_model)  # (B, L, d_model)\r\n",
        "\r\n",
        "print(attn_values.shape)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 512, 20])\n",
            "torch.Size([10, 20, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTng_2SXhdH1",
        "outputId": "e26f3f3b-a223-4e9c-a082-073c2bf73f97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "outputs = w_0(attn_values)\r\n",
        "\r\n",
        "print(outputs)\r\n",
        "print(outputs.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0567, -0.0209,  0.0043,  ..., -0.0531,  0.1738,  0.1426],\n",
            "         [ 0.1409,  0.0459,  0.0512,  ...,  0.0461, -0.0205, -0.0057],\n",
            "         [ 0.0487, -0.0434,  0.1266,  ...,  0.0438,  0.0561, -0.1456],\n",
            "         ...,\n",
            "         [-0.1780,  0.0567, -0.1630,  ..., -0.0976, -0.0459, -0.0163],\n",
            "         [-0.0830, -0.1623, -0.1158,  ..., -0.1331,  0.0338, -0.0714],\n",
            "         [ 0.0985, -0.0279, -0.2172,  ...,  0.0260, -0.0861, -0.0418]],\n",
            "\n",
            "        [[-0.0440, -0.1483, -0.1870,  ..., -0.0452,  0.2920,  0.1776],\n",
            "         [ 0.2851,  0.0721, -0.0379,  ...,  0.1460, -0.0991, -0.0980],\n",
            "         [-0.0392, -0.2991,  0.2465,  ...,  0.0970,  0.1270, -0.2169],\n",
            "         ...,\n",
            "         [-0.5207, -0.1474, -0.2334,  ...,  0.0681, -0.3703,  0.4393],\n",
            "         [-0.3173, -0.5996,  0.0582,  ..., -0.4438,  0.1314, -0.0597],\n",
            "         [ 0.0777,  0.2193, -0.1201,  ...,  0.1036, -0.0339,  0.1314]],\n",
            "\n",
            "        [[ 0.0776, -0.1898, -0.1236,  ...,  0.0252,  0.1498,  0.1471],\n",
            "         [ 0.3411,  0.0330, -0.0211,  ...,  0.2195, -0.0147, -0.0883],\n",
            "         [ 0.1019, -0.1198, -0.0052,  ...,  0.0462,  0.0392, -0.0858],\n",
            "         ...,\n",
            "         [-0.3953, -0.1993, -0.2126,  ...,  0.0783, -0.1861,  0.3177],\n",
            "         [-0.2691, -0.3850, -0.0256,  ..., -0.2397,  0.0596, -0.0044],\n",
            "         [ 0.1506,  0.1128, -0.0723,  ...,  0.0160, -0.0796, -0.0329]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.1140, -0.0885, -0.1365,  ...,  0.0511, -0.1155,  0.0226],\n",
            "         [ 0.1510,  0.0418,  0.1354,  ...,  0.1131,  0.1677,  0.0647],\n",
            "         [-0.0282,  0.0046, -0.0304,  ...,  0.0960, -0.1607,  0.0423],\n",
            "         ...,\n",
            "         [ 0.0060, -0.0204, -0.1046,  ...,  0.0167, -0.0295, -0.0687],\n",
            "         [ 0.1299, -0.0038,  0.0179,  ..., -0.1147, -0.2189, -0.1446],\n",
            "         [ 0.1546, -0.0697, -0.2517,  ...,  0.0493,  0.0250,  0.0066]],\n",
            "\n",
            "        [[ 0.0354, -0.0197, -0.1172,  ...,  0.1256,  0.1509,  0.0471],\n",
            "         [ 0.1455,  0.0114,  0.0790,  ..., -0.0019, -0.1974,  0.0520],\n",
            "         [ 0.0596, -0.0277,  0.1275,  ..., -0.0177,  0.1361, -0.2818],\n",
            "         ...,\n",
            "         [-0.1540,  0.0048, -0.1096,  ...,  0.1310, -0.0851,  0.0831],\n",
            "         [-0.2006, -0.2015,  0.0534,  ..., -0.2179, -0.0455,  0.0167],\n",
            "         [ 0.0871, -0.0193, -0.1079,  ..., -0.0542,  0.0181, -0.0611]],\n",
            "\n",
            "        [[-0.0969, -0.1307, -0.0733,  ...,  0.1407,  0.1152,  0.0225],\n",
            "         [ 0.1203,  0.0652, -0.0153,  ...,  0.0338, -0.0627,  0.0148],\n",
            "         [-0.0230, -0.1222,  0.0688,  ...,  0.0670,  0.0262, -0.1171],\n",
            "         ...,\n",
            "         [-0.1038,  0.0688, -0.1713,  ..., -0.0445, -0.0676,  0.1111],\n",
            "         [-0.1932, -0.3137,  0.0903,  ..., -0.1025, -0.0864,  0.0514],\n",
            "         [ 0.0223,  0.0308, -0.2145,  ...,  0.0678, -0.0521, -0.0279]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "torch.Size([10, 20, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "goX70VKqhxQH"
      },
      "source": [
        "### **전체 코드**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtNyV7mMj7V_"
      },
      "source": [
        "위의 과정을 모두 합쳐 하나의 Multi-head attention 모듈을 구현하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_kNhOTrkBHm"
      },
      "source": [
        "class MultiheadAttention(nn.Module):\r\n",
        "  def __init__(self):\r\n",
        "    super(MultiheadAttention, self).__init__()\r\n",
        "\r\n",
        "    # Q, K, V learnable matrices\r\n",
        "    self.w_q = nn.Linear(d_model, d_model)\r\n",
        "    self.w_k = nn.Linear(d_model, d_model)\r\n",
        "    self.w_v = nn.Linear(d_model, d_model)\r\n",
        "\r\n",
        "    # Linear transformation for concatenated outputs\r\n",
        "    self.w_0 = nn.Linear(d_model, d_model)\r\n",
        "\r\n",
        "  def forward(self, q, k, v):\r\n",
        "    batch_size = q.shape[0]\r\n",
        "\r\n",
        "    q = self.w_q(q)  # (B, L, d_model)\r\n",
        "    k = self.w_k(k)  # (B, L, d_model)\r\n",
        "    v = self.w_v(v)  # (B, L, d_model)\r\n",
        "\r\n",
        "    q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n",
        "    k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n",
        "    v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\r\n",
        "\r\n",
        "    q = q.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n",
        "    k = k.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n",
        "    v = v.transpose(1, 2)  # (B, num_heads, L, d_k)\r\n",
        "\r\n",
        "    attn_values = self.self_attention(q, k, v)  # (B, num_heads, L, d_k)\r\n",
        "    attn_values = attn_values.transpose(1, 2).contiguous().view(batch_size, -1, d_model)  # (B, L, num_heads, d_k) => (B, L, d_model)\r\n",
        "\r\n",
        "    return self.w_0(attn_values)\r\n",
        "\r\n",
        "  def self_attention(self, q, k, v):\r\n",
        "    attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)  # (B, num_heads, L, L)\r\n",
        "    attn_dists = F.softmax(attn_scores, dim=-1)  # (B, num_heads, L, L)\r\n",
        "\r\n",
        "    attn_values = torch.matmul(attn_dists, v)  # (B, num_heads, L, d_k)\r\n",
        "\r\n",
        "    return attn_values"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYLuu_9alQxT"
      },
      "source": [
        "multihead_attn = MultiheadAttention()\r\n",
        "\r\n",
        "outputs = multihead_attn(batch_emb, batch_emb, batch_emb)  # (B, L, d_model)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMiXlYjSlTfB",
        "outputId": "293cfcbe-7752-4beb-dc86-e3529317a81d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(outputs)\r\n",
        "print(outputs.shape)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 0.0448,  0.0268, -0.0891,  ..., -0.0003,  0.0919,  0.0454],\n",
            "         [-0.0024, -0.0347, -0.0528,  ...,  0.0291,  0.0624,  0.0686],\n",
            "         [ 0.0525,  0.0335, -0.0281,  ...,  0.0178,  0.0203,  0.0042],\n",
            "         ...,\n",
            "         [ 0.0149, -0.0504, -0.0462,  ...,  0.0506,  0.0314, -0.0355],\n",
            "         [ 0.0149, -0.0504, -0.0462,  ...,  0.0506,  0.0314, -0.0355],\n",
            "         [ 0.0149, -0.0504, -0.0462,  ...,  0.0506,  0.0314, -0.0355]],\n",
            "\n",
            "        [[-0.1386,  0.0251, -0.1141,  ...,  0.0034, -0.2172, -0.0186],\n",
            "         [-0.1430,  0.0432, -0.1258,  ...,  0.0148, -0.1913,  0.0207],\n",
            "         [-0.1519,  0.0702, -0.0603,  ...,  0.0395, -0.1865,  0.0488],\n",
            "         ...,\n",
            "         [-0.1897,  0.0055, -0.0758,  ...,  0.0074, -0.1392, -0.0149],\n",
            "         [-0.1897,  0.0055, -0.0758,  ...,  0.0074, -0.1392, -0.0149],\n",
            "         [-0.1897,  0.0055, -0.0758,  ...,  0.0074, -0.1392, -0.0149]],\n",
            "\n",
            "        [[-0.0919,  0.0349, -0.0090,  ...,  0.0178, -0.1924,  0.0756],\n",
            "         [-0.0721,  0.0197,  0.0370,  ...,  0.0187, -0.1496,  0.0632],\n",
            "         [-0.0501,  0.0515, -0.0203,  ..., -0.0615, -0.1896,  0.0163],\n",
            "         ...,\n",
            "         [-0.1088,  0.0313,  0.0162,  ...,  0.0497, -0.1117, -0.0184],\n",
            "         [-0.1088,  0.0313,  0.0162,  ...,  0.0497, -0.1117, -0.0184],\n",
            "         [-0.1088,  0.0313,  0.0162,  ...,  0.0497, -0.1117, -0.0184]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[-0.0467,  0.0060,  0.0188,  ...,  0.0663,  0.0572,  0.0524],\n",
            "         [-0.0040, -0.1038,  0.0367,  ...,  0.0700,  0.0798,  0.0782],\n",
            "         [-0.0658,  0.0177,  0.0230,  ...,  0.0131,  0.0690,  0.0063],\n",
            "         ...,\n",
            "         [-0.0020, -0.0515,  0.0056,  ...,  0.0124,  0.0238,  0.0779],\n",
            "         [-0.0334, -0.1129,  0.0624,  ...,  0.0383,  0.0633, -0.0119],\n",
            "         [-0.0294, -0.0248,  0.0308,  ...,  0.0220,  0.0568,  0.0712]],\n",
            "\n",
            "        [[ 0.0748, -0.0094,  0.0356,  ..., -0.0973, -0.1419,  0.0312],\n",
            "         [ 0.0612,  0.0354,  0.0221,  ..., -0.1148, -0.1251,  0.0135],\n",
            "         [ 0.0979, -0.0233,  0.0445,  ..., -0.1025, -0.0919,  0.0233],\n",
            "         ...,\n",
            "         [-0.0004, -0.0165,  0.0752,  ..., -0.0794, -0.0870, -0.0197],\n",
            "         [-0.0004, -0.0165,  0.0752,  ..., -0.0794, -0.0870, -0.0197],\n",
            "         [-0.0004, -0.0165,  0.0752,  ..., -0.0794, -0.0870, -0.0197]],\n",
            "\n",
            "        [[-0.0738, -0.0221,  0.0867,  ...,  0.0113, -0.0489,  0.0005],\n",
            "         [-0.0407,  0.0184,  0.0946,  ..., -0.0089, -0.1141,  0.0092],\n",
            "         [-0.0683,  0.0134,  0.0658,  ..., -0.0078, -0.1006,  0.0029],\n",
            "         ...,\n",
            "         [-0.1137,  0.0131,  0.1411,  ..., -0.0110, -0.0337, -0.0581],\n",
            "         [-0.1137,  0.0131,  0.1411,  ..., -0.0110, -0.0337, -0.0581],\n",
            "         [-0.1137,  0.0131,  0.1411,  ..., -0.0110, -0.0337, -0.0581]]],\n",
            "       grad_fn=<AddBackward0>)\n",
            "torch.Size([10, 20, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ0eoMBJVL8V"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}